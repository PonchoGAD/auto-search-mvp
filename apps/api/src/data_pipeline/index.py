import hashlib
from typing import List
from datetime import datetime, timezone

from qdrant_client.models import PointStruct

from db.models import RawDocument
from integrations.vector_db.qdrant import QdrantStore


# =====================================================
# CONFIG
# =====================================================

VECTOR_SIZE = 32  # MOCK embedding size (MVP, deterministic)


# =====================================================
# EMBEDDING
# =====================================================

def deterministic_embedding(text: str, size: int = VECTOR_SIZE) -> List[float]:
    """
    –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π MOCK embedding.
    –û–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ç–µ–∫—Å—Ç -> –≤—Å–µ–≥–¥–∞ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –≤–µ–∫—Ç–æ—Ä.

    MVP:
    - –±–µ–∑ ML
    - –±—ã—Å—Ç—Ä–æ
    - —Å—Ç–∞–±–∏–ª—å–Ω–æ –¥–ª—è –¥–µ–º–æ
    """
    digest = hashlib.sha256(text.encode("utf-8")).digest()

    vector: List[float] = []
    for i in range(size):
        value = digest[i % len(digest)]
        vector.append(value / 255.0)

    return vector


# =====================================================
# INDEX RAW DOCUMENTS (MAIN ENTRY)
# =====================================================

def index_raw_documents(raw_docs: List[RawDocument]) -> int:
    """
    –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç RawDocument –Ω–∞–ø—Ä—è–º—É—é –≤ Qdrant.

    –ì–ê–†–ê–ù–¢–ò–ò:
    - payload –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º —Å SearchService
    - created_at / created_at_ts / created_at_source –í–°–ï–ì–î–ê –µ—Å—Ç—å
    - –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è demo / prod
    """

    if not raw_docs:
        print("[INDEX][WARN] no raw documents to index")
        return 0

    store = QdrantStore()
    store.create_collection(VECTOR_SIZE)

    points: List[PointStruct] = []
    now = datetime.now(tz=timezone.utc)

    for doc in raw_docs:
        text = (doc.title or "") + "\n" + (doc.content or "")
        text = text.strip()

        if not text:
            continue

        vector = deterministic_embedding(text)

        created_at = doc.created_at or now
        if created_at.tzinfo is None:
            created_at = created_at.replace(tzinfo=timezone.utc)

        payload = {
            # üîë REQUIRED BY SEARCH
            "source": doc.source,
            "url": doc.source_url,

            # OPTIONAL STRUCTURE (–ø–æ—è–≤–∏—Ç—Å—è –ø–æ–∑–∂–µ –ø—Ä–∏ normalize)
            "brand": None,
            "model": None,
            "price": None,
            "mileage": None,
            "fuel": None,
            "region": None,

            # üîë RECENCY (HARDENED)
            "created_at": created_at.isoformat(),
            "created_at_ts": int(created_at.timestamp()),
            "created_at_source": doc.created_at_source or "ingested",
        }

        points.append(
            PointStruct(
                id=f"raw_{doc.id}",  # ‚õë —É–Ω–∏–∫–∞–ª—å–Ω–æ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ
                vector=vector,
                payload=payload,
            )
        )

    if not points:
        print("[INDEX][WARN] no valid points generated")
        return 0

    store.upsert(points)

    print(f"[INDEX] indexed raw documents: {len(points)}")
    return len(points)


# =====================================================
# LEGACY / FALLBACK (–ù–ï –õ–û–ú–ê–ï–ú)
# =====================================================

def run_index(limit: int = 500):
    """
    Legacy indexer.
    –û—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ / —Ä—É—á–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
    """
    print("[INDEX][WARN] run_index() is legacy, prefer index_raw_documents()")
    return 0
