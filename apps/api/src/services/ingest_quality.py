# apps/api/src/services/ingest_quality.py

import re
import yaml
from typing import Optional, Tuple, Dict, Any

# =========================
# CONFIG / DEFAULTS
# =========================

DEFAULT_MIN_SALE_SCORE = int(
    __import__("os").getenv("MIN_SALE_SCORE", "2")
)

# –ø—É—Ç—å –∫ brands.yaml (–µ–¥–∏–Ω—ã–π –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞)
BRANDS_YAML_PATH = "apps/api/src/config/brands.yaml"

# üÜï Anti-noise thresholds (VPS-safe defaults)
DEFAULT_MIN_TEXT_LEN = int(__import__("os").getenv("MIN_TEXT_LEN", "80"))

DEFAULT_MIN_PRICE_RUB = int(__import__("os").getenv("MIN_PRICE_RUB", "150000"))
DEFAULT_MAX_PRICE_RUB = int(__import__("os").getenv("MAX_PRICE_RUB", "20000000"))

DEFAULT_MIN_YEAR = int(__import__("os").getenv("MIN_YEAR", "1995"))
DEFAULT_MAX_MILEAGE_KM = int(__import__("os").getenv("MAX_MILEAGE_KM", "400000"))

# üÜï blacklist words (anti-noise)
DEFAULT_BLACKLIST_WORDS = [
    "–∏—â—É",
    "–∫—É–ø–ª—é",
    "–≤–æ–ø—Ä–æ—Å",
    "–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ",
    "–ø–æ–º–æ–≥–∏—Ç–µ",
    "—á—Ç–æ –ª—É—á—à–µ",
    "—Ä–µ–º–æ–Ω—Ç",
    "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",
    "–æ—à–∏–±–∫–∞",
    "–ø—Ä–æ–±–ª–µ–º–∞",
    "–∑–∞–ø—á–∞—Å—Ç–∏",
    "—Ä–∞–∑–±–æ—Ä",
]

# =========================
# SALE INTENT DICTIONARIES
# =========================

POSITIVE_WORDS_RU = [
    "–ø—Ä–æ–¥–∞–º",
    "–ø—Ä–æ–¥–∞—é",
    "–ø—Ä–æ–¥–∞—ë—Ç—Å—è",
    "–ø—Ä–æ–¥–∞–µ—Ç—Å—è",
    "–ø—Ä–æ–¥–∞–∂–∞",
    "—Å—Ä–æ—á–Ω–æ –ø—Ä–æ–¥–∞–º",
    "—Ç–æ—Ä–≥",
    "–æ–±–º–µ–Ω",
    "—Ä–∞—Å—Å–º–æ—Ç—Ä—é –æ–±–º–µ–Ω",
]

POSITIVE_WORDS_EN = [
    "for sale",
    "sale",
    "selling",
    "sell",
]

NEGATIVE_WORDS_RU = [
    "–∏—â—É",
    "–∫—É–ø–ª—é",
    "–Ω—É–∂–µ–Ω",
    "–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ",
    "–ø–æ–º–æ–≥–∏—Ç–µ",
    "–æ–±—Å—É–∂–¥–µ–Ω–∏–µ",
    "–≤–æ–ø—Ä–æ—Å",
    "—á—Ç–æ –ª—É—á—à–µ",
    "—Ä–µ–º–æ–Ω—Ç",
    "–Ω–µ –∑–∞–≤–æ–¥–∏—Ç—Å—è",
    "–æ—à–∏–±–∫–∞",
    "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",
]

NEGATIVE_WORDS_EN = [
    "looking for",
    "help",
    "question",
    "repair",
]

# –≤–∞–ª—é—Ç—ã / —Ü–µ–Ω–∞ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
PRICE_PATTERN = re.compile(
    r"(\b\d{3,}\b\s?(—Ä—É–±|‚ÇΩ|—Ä\.|\$|‚Ç¨|—Ç—ã—Å|–∫|k))",
    re.IGNORECASE,
)

# üÜï –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–¥ —Ü–µ–Ω—É/–≥–æ–¥/–ø—Ä–æ–±–µ–≥ (–º—è–≥–∫–æ, MVP)
PRICE_ANY_PATTERN = re.compile(
    r"(–¥–æ|<=|<)?\s*(\d+[\d\s]*)\s*(–º–ª–Ω|–º–∏–ª–ª–∏–æ–Ω|m|—Ç—ã—Å|–∫|k|‚ÇΩ|—Ä—É–±|—Ä\.|\$|‚Ç¨)",
    re.IGNORECASE,
)
YEAR_PATTERN = re.compile(r"\b(19\d{2}|20\d{2})\b")
MILEAGE_PATTERN = re.compile(
    r"(–ø—Ä–æ–±–µ–≥)?\s*(–¥–æ|<=|<)?\s*(\d+[\d\s]*)\s*(–∫–º|—Ç—ã—Å)",
    re.IGNORECASE,
)

# üÜï –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã "—ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ"
# (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª–µ: –µ—Å–ª–∏ sale_intent=false –∏ –Ω–µ—Ç price/year/mileage -> skip)
REQUIRED_SIGNALS_ANY = ("price", "year", "mileage")

# üÜï –¥–æ–º–µ–Ω–Ω—ã–µ/—Å–µ—Ä–≤–∏—Å–Ω—ã–µ —à—É–º-–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ –ø—Ä–∏–ª–µ—Ç–∞—é—Ç –∏–∑ –ø–∞—Ä—Å–µ—Ä–æ–≤
NOISE_PATTERNS = [
    re.compile(r"\bhttp(s)?://\S+\b", re.IGNORECASE),
    re.compile(r"\btelegram\.me/\S+\b", re.IGNORECASE),
    re.compile(r"\bt\.me/\S+\b", re.IGNORECASE),
    re.compile(r"\b–ø–æ–¥–ø–∏—Å(—ã–≤–∞–π|—ã–≤–∞)—Ç(—å|–µ—Å—å)\b", re.IGNORECASE),
    re.compile(r"\b–ª–∞–π–∫\b|\b—Ä–µ–ø–æ—Å—Ç\b|\b–ø–æ–¥–µ–ª(–∏—Å—å|–∏—Ç–µ—Å—å)\b", re.IGNORECASE),
]

# =========================
# BRAND CACHE
# =========================

_BRANDS_CACHE = None


def _load_brands():
    global _BRANDS_CACHE

    if _BRANDS_CACHE is not None:
        return _BRANDS_CACHE

    try:
        with open(BRANDS_YAML_PATH, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f) or {}
            _BRANDS_CACHE = data.get("brands", {})
    except Exception:
        _BRANDS_CACHE = {}

    return _BRANDS_CACHE


# =========================
# SALE INTENT
# =========================

def is_sale_intent(text: str, min_score: int = DEFAULT_MIN_SALE_SCORE) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏–µ–º –æ –ø—Ä–æ–¥–∞–∂–µ.

    scoring:
    +2 –∑–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
    +1 –∑–∞ —Ü–µ–Ω—É / –≤–∞–ª—é—Ç—É
    -2 –∑–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞

    sale_intent = score >= min_score
    """

    if not text:
        return False

    text = text.lower()
    score = 0

    # –ø–æ–∑–∏—Ç–∏–≤
    for w in POSITIVE_WORDS_RU + POSITIVE_WORDS_EN:
        if w in text:
            score += 2

    # —Ü–µ–Ω–∞
    if PRICE_PATTERN.search(text):
        score += 1

    # –Ω–µ–≥–∞—Ç–∏–≤
    for w in NEGATIVE_WORDS_RU + NEGATIVE_WORDS_EN:
        if w in text:
            score -= 2

    return score >= min_score


# =========================
# BRAND DETECTION
# =========================

def detect_brand(text: str) -> Tuple[Optional[str], float]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      (brand_key | None, confidence)

    confidence:
      exact = 1.0
      alias = 0.7
    """

    if not text:
        return None, 0.0

    text = text.lower()
    brands = _load_brands()

    for brand_key, cfg in brands.items():
        # exact en
        for v in cfg.get("en", []):
            if v.lower() in text:
                return brand_key, 1.0

        # exact ru
        for v in cfg.get("ru", []):
            if v.lower() in text:
                return brand_key, 1.0

        # aliases
        for v in cfg.get("aliases", []):
            if v.lower() in text:
                return brand_key, 0.7

    return None, 0.0


# =========================
# META PREFIX (MVP MODE)
# =========================

def build_meta_prefix(
    *,
    brand: Optional[str],
    brand_confidence: float,
    sale_intent: bool,
    source_boost: float,
) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç meta-prefix –¥–ª—è content –±–µ–∑ –º–∏–≥—Ä–∞—Ü–∏–π –ë–î.

    –§–æ—Ä–º–∞—Ç:
    __meta__: brand=bmw; brand_conf=1.0; sale_intent=1; source_boost=1.5
    """

    return (
        "__meta__: "
        f"brand={brand or 'none'}; "
        f"brand_conf={round(brand_confidence, 2)}; "
        f"sale_intent={1 if sale_intent else 0}; "
        f"source_boost={round(source_boost, 2)}"
    )


# =========================
# SOURCE BOOST
# =========================

SOURCE_BOOSTS = {
    "forum": 1.5,
    "telegram": 1.0,
    "marketplace": 0.8,
}


def resolve_source_boost(source: str) -> float:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç source -> boost.
    """

    if not source:
        return 1.0

    s = source.lower()

    if "club" in s or "forum" in s:
        return SOURCE_BOOSTS["forum"]

    if "telegram" in s:
        return SOURCE_BOOSTS["telegram"]

    return SOURCE_BOOSTS["marketplace"]


# =========================
# üÜï ANTI-NOISE HELPERS
# =========================

def normalize_text_for_rules(text: str) -> str:
    """
    –ú—è–≥–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–∞–≤–∏–ª:
    - lower
    - —Å—Ö–ª–æ–ø –ø—Ä–æ–±–µ–ª—ã
    - —É–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —à—É–º–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã (—Å—Å—ã–ª–∫–∏/–ø—Ä–∏–∑—ã–≤—ã)
    """
    t = (text or "").lower()
    t = re.sub(r"\s+", " ", t).strip()

    # —É–¥–∞–ª—è–µ–º —è–≤–Ω–æ —à—É–º–æ–≤—ã–µ –∫—É—Å–∫–∏ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —ç–≤—Ä–∏—Å—Ç–∏–∫)
    for pat in NOISE_PATTERNS:
        t = pat.sub(" ", t)

    t = re.sub(r"\s+", " ", t).strip()
    return t


def has_blacklist_words(text: str, blacklist: Optional[list] = None) -> bool:
    """
    True –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —è–≤–Ω–æ "–º—É—Å–æ—Ä" (–∏—â—É/–≤–æ–ø—Ä–æ—Å/—Ä–µ–º–æ–Ω—Ç/–∑–∞–ø—á–∞—Å—Ç–∏ –∏ —Ç.–ø.)
    """
    if not text:
        return True

    blacklist = blacklist or DEFAULT_BLACKLIST_WORDS
    t = normalize_text_for_rules(text)

    for w in blacklist:
        if w and w.lower() in t:
            return True
    return False


def parse_price_rub(text: str) -> Optional[int]:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –≤—ã—Ç–∞—â–∏—Ç—å —Ü–µ–Ω—É –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ RUB (–æ—á–µ–Ω—å –≥—Ä—É–±–æ, MVP).
    –ï—Å–ª–∏ $/‚Ç¨ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ None (–Ω–µ —É–≤–µ—Ä–µ–Ω—ã).
    """
    if not text:
        return None

    t = normalize_text_for_rules(text)
    m = PRICE_ANY_PATTERN.search(t)
    if not m:
        return None

    raw = m.group(2)
    unit = (m.group(3) or "").lower()

    try:
        val = int(raw.replace(" ", ""))
    except Exception:
        return None

    if unit in ["–º–ª–Ω", "–º–∏–ª–ª–∏–æ–Ω", "m"]:
        val *= 1_000_000
    elif unit in ["—Ç—ã—Å", "–∫", "k"]:
        val *= 1_000
    elif unit in ["$", "‚Ç¨"]:
        # MVP: –Ω–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏–º –±–µ–∑ –∫—É—Ä—Å–∞
        return None

    return val


def parse_year(text: str) -> Optional[int]:
    if not text:
        return None
    t = normalize_text_for_rules(text)
    m = YEAR_PATTERN.search(t)
    if not m:
        return None
    try:
        y = int(m.group(1))
        return y
    except Exception:
        return None


def parse_mileage_km(text: str) -> Optional[int]:
    """
    –ò—â–µ—Ç –ø—Ä–æ–±–µ–≥: '–¥–æ 120 —Ç—ã—Å', '120 000 –∫–º'
    """
    if not text:
        return None

    t = normalize_text_for_rules(text)
    m = MILEAGE_PATTERN.search(t)
    if not m:
        return None

    raw = m.group(3)
    unit = (m.group(4) or "").lower()

    try:
        val = int(raw.replace(" ", ""))
    except Exception:
        return None

    if unit == "—Ç—ã—Å":
        val *= 1000

    return val


def extract_quality_signals(text: str) -> Dict[str, Any]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –±–∞–∑–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∫–∞—á–µ—Å—Ç–≤–∞ (–¥–ª—è explain / –ª–æ–≥–æ–≤ / –æ—Ç–±–æ—Ä–∞).
    """
    price = parse_price_rub(text)
    year = parse_year(text)
    mileage = parse_mileage_km(text)

    return {
        "price_rub": price,
        "year": year,
        "mileage_km": mileage,
        "has_price": price is not None,
        "has_year": year is not None,
        "has_mileage": mileage is not None,
    }


def passes_min_max_rules(
    *,
    text: str,
    min_text_len: int = DEFAULT_MIN_TEXT_LEN,
    min_price_rub: int = DEFAULT_MIN_PRICE_RUB,
    max_price_rub: int = DEFAULT_MAX_PRICE_RUB,
    min_year: int = DEFAULT_MIN_YEAR,
    max_mileage_km: int = DEFAULT_MAX_MILEAGE_KM,
) -> Tuple[bool, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (ok, reason)
    """
    if not text or len((text or "").strip()) < min_text_len:
        return False, "text_too_short"

    signals = extract_quality_signals(text)

    # price
    price = signals["price_rub"]
    if price is not None:
        if price < min_price_rub:
            return False, "price_too_low"
        if price > max_price_rub:
            return False, "price_too_high"

    # year
    year = signals["year"]
    if year is not None:
        if year < min_year:
            return False, "year_too_old"

    # mileage
    mileage = signals["mileage_km"]
    if mileage is not None:
        if mileage > max_mileage_km:
            return False, "mileage_too_high"

    return True, "ok"


def has_any_required_signals(text: str) -> bool:
    """
    True –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏–∑ —Å–∏–≥–Ω–∞–ª–æ–≤: —Ü–µ–Ω–∞ / –≥–æ–¥ / –ø—Ä–æ–±–µ–≥.
    –ù—É–∂–µ–Ω –¥–ª—è –ø—Ä–∞–≤–∏–ª–∞:
    "–µ—Å–ª–∏ sale_intent=false –∏ –Ω–µ—Ç —Ü–µ–Ω—ã/–≥–æ–¥–∞/–ø—Ä–æ–±–µ–≥–∞ ‚Äî skip"
    """
    signals = extract_quality_signals(text)
    return bool(signals.get("has_price") or signals.get("has_year") or signals.get("has_mileage"))


# =========================
# üÜï STATS (IN-MEMORY)
# =========================

class SkipStats:
    """
    In-memory —Å—á—ë—Ç—á–∏–∫ –ø—Ä–∏—á–∏–Ω –æ—Ç—Å–µ–≤–∞.
    - VPS-safe (–±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
    - –ú–æ–∂–Ω–æ –ø–µ—á–∞—Ç–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ N –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    """

    def __init__(self):
        self.total: int = 0
        self.kept: int = 0
        self.skipped: int = 0
        self.by_reason: Dict[str, int] = {}

    def add(self, *, skip: bool, reason: str):
        self.total += 1
        if skip:
            self.skipped += 1
            self.by_reason[reason] = self.by_reason.get(reason, 0) + 1
        else:
            self.kept += 1

    def snapshot(self) -> Dict[str, Any]:
        return {
            "total": self.total,
            "kept": self.kept,
            "skipped": self.skipped,
            "by_reason": dict(sorted(self.by_reason.items(), key=lambda x: x[1], reverse=True)),
        }

    def log(self, prefix: str = "[INGEST][ANTI_NOISE]"):
        snap = self.snapshot()
        print(
            f"{prefix} total={snap['total']} kept={snap['kept']} skipped={snap['skipped']} reasons={snap['by_reason']}"
        )


# =========================
# MAIN DECISION: SHOULD SKIP
# =========================

def should_skip_doc(
    *,
    text: str,
    source: str = "",
    min_sale_score: int = DEFAULT_MIN_SALE_SCORE,
    blacklist: Optional[list] = None,
) -> Tuple[bool, Dict[str, Any]]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Anti-noise.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      (skip, meta)
    meta —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É.

    –í–ê–ñ–ù–û:
    - –ù–ï –î–û–õ–ñ–ù–ê –±—Ä–æ—Å–∞—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏—è –Ω–∞—Ä—É–∂—É.
    - –î–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±—ã—Å—Ç—Ä—ã–º —Ñ–∏–ª—å—Ç—Ä–æ–º –¥–æ –∑–∞–ø–∏—Å–∏ RawDocument –∏ –¥–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ Qdrant.
    """
    meta: Dict[str, Any] = {}

    try:
        if not text:
            meta["reason"] = "empty_text"
            return True, meta

        # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª (–∏—Å—Ö–æ–¥–Ω—ã–π text —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å)
        norm = normalize_text_for_rules(text)
        meta["source"] = source or ""
        meta["text_len"] = len(norm)

        # 1) blacklist words
        if has_blacklist_words(norm, blacklist=blacklist):
            meta["reason"] = "blacklist_word"
            return True, meta

        # 2) min/max rules
        ok, reason = passes_min_max_rules(text=norm)
        if not ok:
            meta["reason"] = reason
            return True, meta

        # 3) sale intent
        sale = is_sale_intent(norm, min_score=min_sale_score)
        meta["sale_intent"] = sale

        # 4) –ø—Ä–∞–≤–∏–ª–æ: –µ—Å–ª–∏ sale_intent=false –∏ –Ω–µ—Ç price/year/mileage ‚Äî skip
        #    (–∏–Ω–∞—á–µ –∏–Ω–æ–≥–¥–∞ –ø—Ä–æ–ª–µ—Ç–∞—é—Ç "–ø—Ä–∏–≤–µ—Ç –≤—Å–µ–º" –∏ –ø—Ä–æ—á–∏–π —Ñ–ª—É–¥)
        if not sale:
            if not has_any_required_signals(norm):
                meta["reason"] = "not_sale_and_no_signals"
                return True, meta

            # –µ—Å–ª–∏ —Å–∏–≥–Ω–∞–ª—ã –µ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä —Ü–µ–Ω–∞/–≥–æ–¥/–ø—Ä–æ–±–µ–≥), –Ω–æ sale_intent —Å–ª–∞–±—ã–π
            # –æ—Å—Ç–∞–≤–ª—è–µ–º —à–∞–Ω—Å (MVP), –Ω–æ –ø–æ–º–µ—Ç–∏–º:
            meta["reason"] = "weak_sale_but_has_signals"
            return False, meta

        meta["reason"] = "ok"
        return False, meta

    except Exception as e:
        # fail-safe: –ª—É—á—à–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç, —á–µ–º –ø–æ–ª–æ–º–∞—Ç—å ingest
        meta["reason"] = "exception"
        meta["error"] = str(e)
        return True, meta


# =========================
# üÜï META UTILITIES
# =========================

META_LINE_RE = re.compile(r"^__meta__:\s*(.*)$", re.IGNORECASE)


def extract_meta_from_text(text: str) -> Dict[str, Any]:
    """
    –ï—Å–ª–∏ content –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "__meta__: k=v; ..." ‚Äî —Ä–∞—Å–ø–∞—Ä—Å–∏–º.
    """
    if not text:
        return {}

    first_line = text.splitlines()[0].strip()
    m = META_LINE_RE.match(first_line)
    if not m:
        return {}

    body = m.group(1)
    parts = [p.strip() for p in body.split(";") if p.strip()]
    out: Dict[str, Any] = {}
    for p in parts:
        if "=" not in p:
            continue
        k, v = p.split("=", 1)
        out[k.strip()] = v.strip()
    return out


def apply_meta_prefix(text: str, meta_prefix: str) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç meta-prefix –≤ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –µ–≥–æ —Ç–∞–º –µ—â—ë –Ω–µ—Ç.
    """
    if not text:
        return text
    if text.lstrip().lower().startswith("__meta__:"):
        return text
    return f"{meta_prefix}\n{text}"


# =========================
# üÜï ONE-SHOT: BUILD META + APPLY
# =========================

def enrich_text_with_meta(
    *,
    raw_text: str,
    source: str,
) -> Tuple[str, Dict[str, Any]]:
    """
    –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è ingest.py:

    1) detect_brand
    2) is_sale_intent
    3) resolve_source_boost
    4) build_meta_prefix
    5) apply_meta_prefix

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      - content_with_meta (str)
      - meta (dict) —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π (brand, conf, sale_intent, boost)
    """
    meta: Dict[str, Any] = {}

    brand, brand_conf = detect_brand(raw_text)
    sale = is_sale_intent(raw_text)
    boost = resolve_source_boost(source)

    meta["brand"] = brand
    meta["brand_confidence"] = float(brand_conf)
    meta["sale_intent"] = bool(sale)
    meta["source_boost"] = float(boost)

    meta_prefix = build_meta_prefix(
        brand=brand,
        brand_confidence=brand_conf,
        sale_intent=sale,
        source_boost=boost,
    )

    content = apply_meta_prefix(raw_text, meta_prefix)
    return content, meta
